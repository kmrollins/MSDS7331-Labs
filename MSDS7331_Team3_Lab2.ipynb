{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSDS 7331: Data Mining\n",
    "## Lab 2: Classification\n",
    "## 7 July 2019\n",
    "## Authors: Meredith Ludlow, Anand Rajan, Kristen Rollins, and Tej Tenmattam\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 1:</b> Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two classification tasks for our 2017 census dataset are to predict whether a given census tract has a high or a low unemployment rate, as well as a high or low child poverty rate, based on other relevant factors. This is an important task, as it enables certain areas to be flagged as needing economic development or aid. Below, we first prepared our data for classification by cleaning it (in the same way as Lab 1), as well as removing unnecessary and redundant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seaborn plot styles\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_color_codes('muted')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignore warnings for clean report\n",
    "\n",
    "# df.head() displays all the columns without truncating\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# read csv file as pandas dataframe\n",
    "df_17_census = pd.read_csv('Data/acs2017_census_tract_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset as in lab 1\n",
    "df_17_census.set_index('TractId', inplace=True) # set tract id as index\n",
    "\n",
    "# Drop tracts where population is 0\n",
    "df_17_cln = df_17_census.drop(df_17_census[df_17_census.TotalPop == 0].index)\n",
    "\n",
    "# Drop tracts where child poverty or unemployment is null\n",
    "df_17_cln = df_17_cln[np.isfinite(df_17_cln['ChildPoverty'])]\n",
    "df_17_cln = df_17_cln[np.isfinite(df_17_cln['Unemployment'])]\n",
    "\n",
    "# Impute to the median by each state\n",
    "df_grouped = df_17_cln.groupby('State').transform(lambda x: x.fillna(x.median()))\n",
    "df_17_cln['Income'] = df_grouped['Income']\n",
    "df_17_cln['IncomeErr'] = df_grouped['IncomeErr']\n",
    "\n",
    "# Impute remaining values to the overall median\n",
    "df_17_cln = df_17_cln.fillna(df_17_cln.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Pacific</th>\n",
       "      <th>VotingAgeCitizen</th>\n",
       "      <th>Income</th>\n",
       "      <th>IncomeErr</th>\n",
       "      <th>IncomePerCap</th>\n",
       "      <th>IncomePerCapErr</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>ChildPoverty</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Service</th>\n",
       "      <th>Office</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Production</th>\n",
       "      <th>Drive</th>\n",
       "      <th>Carpool</th>\n",
       "      <th>Transit</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.00000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "      <td>72889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4438.372759</td>\n",
       "      <td>2182.350698</td>\n",
       "      <td>2256.022061</td>\n",
       "      <td>17.290081</td>\n",
       "      <td>61.312817</td>\n",
       "      <td>13.268165</td>\n",
       "      <td>0.729703</td>\n",
       "      <td>4.752853</td>\n",
       "      <td>0.146698</td>\n",
       "      <td>3137.878459</td>\n",
       "      <td>61111.961002</td>\n",
       "      <td>9694.920825</td>\n",
       "      <td>30702.626734</td>\n",
       "      <td>4259.381073</td>\n",
       "      <td>16.067164</td>\n",
       "      <td>21.155081</td>\n",
       "      <td>35.566003</td>\n",
       "      <td>18.855030</td>\n",
       "      <td>23.407072</td>\n",
       "      <td>9.256663</td>\n",
       "      <td>12.915429</td>\n",
       "      <td>75.823635</td>\n",
       "      <td>9.323555</td>\n",
       "      <td>5.387234</td>\n",
       "      <td>2.95396</td>\n",
       "      <td>1.888721</td>\n",
       "      <td>4.623234</td>\n",
       "      <td>26.078983</td>\n",
       "      <td>2078.009535</td>\n",
       "      <td>79.506605</td>\n",
       "      <td>14.151449</td>\n",
       "      <td>6.170819</td>\n",
       "      <td>0.171328</td>\n",
       "      <td>7.235223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2192.532931</td>\n",
       "      <td>1101.516460</td>\n",
       "      <td>1126.275010</td>\n",
       "      <td>23.097490</td>\n",
       "      <td>30.635700</td>\n",
       "      <td>21.598962</td>\n",
       "      <td>4.525143</td>\n",
       "      <td>8.992743</td>\n",
       "      <td>1.023074</td>\n",
       "      <td>1514.686755</td>\n",
       "      <td>30492.084659</td>\n",
       "      <td>6135.953813</td>\n",
       "      <td>16059.781976</td>\n",
       "      <td>3019.532445</td>\n",
       "      <td>12.514595</td>\n",
       "      <td>18.643563</td>\n",
       "      <td>15.093914</td>\n",
       "      <td>8.037855</td>\n",
       "      <td>5.653534</td>\n",
       "      <td>5.979854</td>\n",
       "      <td>7.629365</td>\n",
       "      <td>15.062128</td>\n",
       "      <td>5.167761</td>\n",
       "      <td>11.659900</td>\n",
       "      <td>5.39858</td>\n",
       "      <td>2.518341</td>\n",
       "      <td>3.821944</td>\n",
       "      <td>7.101069</td>\n",
       "      <td>1121.667248</td>\n",
       "      <td>8.017414</td>\n",
       "      <td>7.224480</td>\n",
       "      <td>3.846069</td>\n",
       "      <td>0.455440</td>\n",
       "      <td>5.177195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2692.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>949.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2953.000000</td>\n",
       "      <td>1438.000000</td>\n",
       "      <td>1491.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2093.000000</td>\n",
       "      <td>40400.000000</td>\n",
       "      <td>5740.000000</td>\n",
       "      <td>20603.000000</td>\n",
       "      <td>2507.000000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>72.300000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>1302.000000</td>\n",
       "      <td>75.300000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4133.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>70.400000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2924.000000</td>\n",
       "      <td>54434.000000</td>\n",
       "      <td>8273.000000</td>\n",
       "      <td>27242.000000</td>\n",
       "      <td>3405.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>79.900000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.40000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>1913.000000</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5530.000000</td>\n",
       "      <td>2717.000000</td>\n",
       "      <td>2815.000000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>87.700000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3920.000000</td>\n",
       "      <td>74673.000000</td>\n",
       "      <td>11899.000000</td>\n",
       "      <td>36429.000000</td>\n",
       "      <td>4965.000000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>44.900000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>84.900000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>3.30000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>30.300000</td>\n",
       "      <td>2649.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65528.000000</td>\n",
       "      <td>32266.000000</td>\n",
       "      <td>33262.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>91.400000</td>\n",
       "      <td>71.900000</td>\n",
       "      <td>39389.000000</td>\n",
       "      <td>249750.000000</td>\n",
       "      <td>153365.000000</td>\n",
       "      <td>220253.000000</td>\n",
       "      <td>84414.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>73.900000</td>\n",
       "      <td>28945.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TotalPop           Men         Women      Hispanic         White  \\\n",
       "count  72889.000000  72889.000000  72889.000000  72889.000000  72889.000000   \n",
       "mean    4438.372759   2182.350698   2256.022061     17.290081     61.312817   \n",
       "std     2192.532931   1101.516460   1126.275010     23.097490     30.635700   \n",
       "min        4.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     2953.000000   1438.000000   1491.000000      2.600000     38.100000   \n",
       "50%     4133.000000   2022.000000   2100.000000      7.400000     70.400000   \n",
       "75%     5530.000000   2717.000000   2815.000000     21.100000     87.700000   \n",
       "max    65528.000000  32266.000000  33262.000000    100.000000    100.000000   \n",
       "\n",
       "              Black        Native         Asian       Pacific  \\\n",
       "count  72889.000000  72889.000000  72889.000000  72889.000000   \n",
       "mean      13.268165      0.729703      4.752853      0.146698   \n",
       "std       21.598962      4.525143      8.992743      1.023074   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.800000      0.000000      0.200000      0.000000   \n",
       "50%        3.800000      0.000000      1.500000      0.000000   \n",
       "75%       14.500000      0.400000      5.000000      0.000000   \n",
       "max      100.000000    100.000000     91.400000     71.900000   \n",
       "\n",
       "       VotingAgeCitizen         Income      IncomeErr   IncomePerCap  \\\n",
       "count      72889.000000   72889.000000   72889.000000   72889.000000   \n",
       "mean        3137.878459   61111.961002    9694.920825   30702.626734   \n",
       "std         1514.686755   30492.084659    6135.953813   16059.781976   \n",
       "min            1.000000    2692.000000     728.000000     949.000000   \n",
       "25%         2093.000000   40400.000000    5740.000000   20603.000000   \n",
       "50%         2924.000000   54434.000000    8273.000000   27242.000000   \n",
       "75%         3920.000000   74673.000000   11899.000000   36429.000000   \n",
       "max        39389.000000  249750.000000  153365.000000  220253.000000   \n",
       "\n",
       "       IncomePerCapErr       Poverty  ChildPoverty  Professional  \\\n",
       "count     72889.000000  72889.000000  72889.000000  72889.000000   \n",
       "mean       4259.381073     16.067164     21.155081     35.566003   \n",
       "std        3019.532445     12.514595     18.643563     15.093914   \n",
       "min         308.000000      0.000000      0.000000      0.000000   \n",
       "25%        2507.000000      6.900000      6.200000     24.700000   \n",
       "50%        3405.000000     12.600000     16.300000     33.300000   \n",
       "75%        4965.000000     21.800000     31.600000     44.900000   \n",
       "max       84414.000000    100.000000    100.000000    100.000000   \n",
       "\n",
       "            Service        Office  Construction    Production         Drive  \\\n",
       "count  72889.000000  72889.000000  72889.000000  72889.000000  72889.000000   \n",
       "mean      18.855030     23.407072      9.256663     12.915429     75.823635   \n",
       "std        8.037855      5.653534      5.979854      7.629365     15.062128   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       13.300000     19.700000      5.000000      7.100000     72.300000   \n",
       "50%       17.700000     23.200000      8.400000     11.800000     79.900000   \n",
       "75%       23.300000     26.900000     12.500000     17.500000     84.900000   \n",
       "max      100.000000    100.000000    100.000000    100.000000    100.000000   \n",
       "\n",
       "            Carpool       Transit         Walk   OtherTransp    WorkAtHome  \\\n",
       "count  72889.000000  72889.000000  72889.00000  72889.000000  72889.000000   \n",
       "mean       9.323555      5.387234      2.95396      1.888721      4.623234   \n",
       "std        5.167761     11.659900      5.39858      2.518341      3.821944   \n",
       "min        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
       "25%        5.800000      0.000000      0.40000      0.400000      2.000000   \n",
       "50%        8.500000      1.000000      1.40000      1.200000      3.800000   \n",
       "75%       11.900000      4.600000      3.30000      2.500000      6.300000   \n",
       "max      100.000000    100.000000    100.00000    100.000000    100.000000   \n",
       "\n",
       "        MeanCommute      Employed   PrivateWork    PublicWork  SelfEmployed  \\\n",
       "count  72889.000000  72889.000000  72889.000000  72889.000000  72889.000000   \n",
       "mean      26.078983   2078.009535     79.506605     14.151449      6.170819   \n",
       "std        7.101069   1121.667248      8.017414      7.224480      3.846069   \n",
       "min        4.200000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       21.100000   1302.000000     75.300000      9.300000      3.500000   \n",
       "50%       25.400000   1913.000000     80.600000     13.000000      5.500000   \n",
       "75%       30.300000   2649.000000     85.000000     17.600000      8.000000   \n",
       "max       73.900000  28945.000000    100.000000    100.000000    100.000000   \n",
       "\n",
       "         FamilyWork  Unemployment  \n",
       "count  72889.000000  72889.000000  \n",
       "mean       0.171328      7.235223  \n",
       "std        0.455440      5.177195  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      3.900000  \n",
       "50%        0.000000      6.000000  \n",
       "75%        0.000000      9.000000  \n",
       "max       22.300000    100.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_17_cln.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72889 entries, 1001020100 to 72153750602\n",
      "Data columns (total 38 columns):\n",
      "State               72889 non-null object\n",
      "County              72889 non-null object\n",
      "TotalPop            72889 non-null int64\n",
      "Men                 72889 non-null int64\n",
      "Women               72889 non-null int64\n",
      "Hispanic            72889 non-null float64\n",
      "White               72889 non-null float64\n",
      "Black               72889 non-null float64\n",
      "Native              72889 non-null float64\n",
      "Asian               72889 non-null float64\n",
      "Pacific             72889 non-null float64\n",
      "VotingAgeCitizen    72889 non-null int64\n",
      "Income              72889 non-null float64\n",
      "IncomeErr           72889 non-null float64\n",
      "IncomePerCap        72889 non-null float64\n",
      "IncomePerCapErr     72889 non-null float64\n",
      "Poverty             72889 non-null float64\n",
      "ChildPoverty        72889 non-null float64\n",
      "Professional        72889 non-null float64\n",
      "Service             72889 non-null float64\n",
      "Office              72889 non-null float64\n",
      "Construction        72889 non-null float64\n",
      "Production          72889 non-null float64\n",
      "Drive               72889 non-null float64\n",
      "Carpool             72889 non-null float64\n",
      "Transit             72889 non-null float64\n",
      "Walk                72889 non-null float64\n",
      "OtherTransp         72889 non-null float64\n",
      "WorkAtHome          72889 non-null float64\n",
      "MeanCommute         72889 non-null float64\n",
      "Employed            72889 non-null int64\n",
      "PrivateWork         72889 non-null float64\n",
      "PublicWork          72889 non-null float64\n",
      "SelfEmployed        72889 non-null float64\n",
      "FamilyWork          72889 non-null float64\n",
      "Unemployment        72889 non-null float64\n",
      "HighUnemployment    72889 non-null int64\n",
      "HighChildPoverty    72889 non-null int64\n",
      "dtypes: float64(29), int64(7), object(2)\n",
      "memory usage: 21.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Categorize the unemployed percentages into binary categories\n",
    "# Make cutoff using median of clean dataset, so groups are roughly equal\n",
    "df_17_cln['HighUnemployment'] = pd.cut(df_17_cln.Unemployment,[-1,6,101],labels=[0,1])     \n",
    "df_17_cln.HighUnemployment = df_17_cln.HighUnemployment.astype(np.int)\n",
    "# 0 indicates low unemployment rate, 1 indicates high unemployment rate\n",
    "\n",
    "# Categorize the child poverty percentages into binary categories\n",
    "# Make cutoff using median of clean dataset, so groups are roughly equal\n",
    "df_17_cln['HighChildPoverty'] = pd.cut(df_17_cln.ChildPoverty,[-1,16.3,101],labels=[0,1])\n",
    "df_17_cln.HighChildPoverty = df_17_cln.HighChildPoverty.astype(np.int)\n",
    "# 0 indicates low child poverty rate, 1 indicates high child poverty rate\n",
    "\n",
    "df_17_cln.info() # matches cleaned dataset from lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have a clean dataset with no missing values, that matches the info from the cleaned dataset we used in Lab 1. Our target variables are \"HighUnemployment\" and \"HighChildPoverty\", which we encoded so that 1 signifies a tract with a high unemployment rate or high child poverty rate and a 0 indicates low unemployment or low child poverty respectively. We created the cutoff between high and low unemployment to be 6 percent, which was the median value for the unemployment attribute. Similarly, we used the median value of 16.3 as the cutoff for high and low child poverty rates. By using the median to separate the groups, the classes will be of roughly the same size.\n",
    "\n",
    "Since this dataset has 38 variables, next we eliminate some unnecessary and redundant variables to cut down on the high dimensionality of the dataset. Here we eliminate variables based on the pairwise correlation plot we created in Lab 1 and intuition. In the Mini Lab, we further reduced the dataset down to only 6 important features based on PCA, but the models using that dataset were not as accurate. Thus we will use this \"full\" dataset of 28 variables throughout this lab.\n",
    "\n",
    "Here we also do a bit of scaling, so that the previously integer attributes are now percentages. In this way most of the predictors are percentages of the total population. However, we will do further scaling when creating our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72889 entries, 1001020100 to 72153750602\n",
      "Data columns (total 28 columns):\n",
      "TotalPop            72889 non-null int64\n",
      "Women               72889 non-null float64\n",
      "Hispanic            72889 non-null float64\n",
      "White               72889 non-null float64\n",
      "Black               72889 non-null float64\n",
      "Native              72889 non-null float64\n",
      "Asian               72889 non-null float64\n",
      "Pacific             72889 non-null float64\n",
      "VotingAgeCitizen    72889 non-null float64\n",
      "Income              72889 non-null float64\n",
      "Poverty             72889 non-null float64\n",
      "Professional        72889 non-null float64\n",
      "Service             72889 non-null float64\n",
      "Office              72889 non-null float64\n",
      "Construction        72889 non-null float64\n",
      "Production          72889 non-null float64\n",
      "Drive               72889 non-null float64\n",
      "Carpool             72889 non-null float64\n",
      "Walk                72889 non-null float64\n",
      "OtherTransp         72889 non-null float64\n",
      "WorkAtHome          72889 non-null float64\n",
      "MeanCommute         72889 non-null float64\n",
      "Employed            72889 non-null float64\n",
      "PrivateWork         72889 non-null float64\n",
      "SelfEmployed        72889 non-null float64\n",
      "FamilyWork          72889 non-null float64\n",
      "HighUnemployment    72889 non-null int64\n",
      "HighChildPoverty    72889 non-null int64\n",
      "dtypes: float64(25), int64(3)\n",
      "memory usage: 16.1 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Pacific</th>\n",
       "      <th>VotingAgeCitizen</th>\n",
       "      <th>Income</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Service</th>\n",
       "      <th>Office</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Production</th>\n",
       "      <th>Drive</th>\n",
       "      <th>Carpool</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>HighUnemployment</th>\n",
       "      <th>HighChildPoverty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TractId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001020100</th>\n",
       "      <td>1845</td>\n",
       "      <td>51.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.3</td>\n",
       "      <td>67826.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>22.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>94.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>47.8</td>\n",
       "      <td>74.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001020200</th>\n",
       "      <td>2172</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>41287.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>30.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>15.4</td>\n",
       "      <td>90.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>39.2</td>\n",
       "      <td>75.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001020300</th>\n",
       "      <td>3385</td>\n",
       "      <td>54.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>73.3</td>\n",
       "      <td>46806.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>27.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>33.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>88.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>43.8</td>\n",
       "      <td>73.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001020400</th>\n",
       "      <td>4267</td>\n",
       "      <td>53.1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>80.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.3</td>\n",
       "      <td>55895.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>25.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>19.5</td>\n",
       "      <td>82.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>43.3</td>\n",
       "      <td>75.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001020500</th>\n",
       "      <td>9965</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.5</td>\n",
       "      <td>68143.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>48.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>86.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>71.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TotalPop  Women  Hispanic  White  Black  Native  Asian  Pacific  \\\n",
       "TractId                                                                       \n",
       "1001020100      1845   51.3       2.4   86.3    5.2     0.0    1.2      0.0   \n",
       "1001020200      2172   46.3       1.1   41.6   54.5     0.0    1.0      0.0   \n",
       "1001020300      3385   54.7       8.0   61.4   26.5     0.6    0.7      0.4   \n",
       "1001020400      4267   53.1       9.6   80.3    7.1     0.5    0.2      0.0   \n",
       "1001020500      9965   49.3       0.9   77.5   16.4     0.0    3.1      0.0   \n",
       "\n",
       "            VotingAgeCitizen   Income  Poverty  Professional  Service  Office  \\\n",
       "TractId                                                                         \n",
       "1001020100              76.3  67826.0     10.7          38.5     15.6    22.8   \n",
       "1001020200              76.1  41287.0     22.4          30.5     24.9    22.9   \n",
       "1001020300              73.3  46806.0     14.7          27.9     19.4    33.3   \n",
       "1001020400              76.3  55895.0      2.3          29.0     16.6    25.8   \n",
       "1001020500              72.5  68143.0     12.2          48.8     13.8    20.5   \n",
       "\n",
       "            Construction  Production  Drive  Carpool  Walk  OtherTransp  \\\n",
       "TractId                                                                   \n",
       "1001020100          10.8        12.4   94.2      3.3   0.5          0.0   \n",
       "1001020200           6.3        15.4   90.5      9.1   0.0          0.5   \n",
       "1001020300           9.9         9.6   88.3      8.4   1.0          0.8   \n",
       "1001020400           9.1        19.5   82.3     11.2   1.5          2.9   \n",
       "1001020500           3.5        13.4   86.9     11.2   0.8          0.3   \n",
       "\n",
       "            WorkAtHome  MeanCommute  Employed  PrivateWork  SelfEmployed  \\\n",
       "TractId                                                                    \n",
       "1001020100         2.1         24.5      47.8         74.2           4.5   \n",
       "1001020200         0.0         22.2      39.2         75.9           9.0   \n",
       "1001020300         1.5         23.1      43.8         73.3           4.8   \n",
       "1001020400         2.1         25.9      43.3         75.8           4.5   \n",
       "1001020500         0.7         21.0      48.0         71.4           4.5   \n",
       "\n",
       "            FamilyWork  HighUnemployment  HighChildPoverty  \n",
       "TractId                                                     \n",
       "1001020100         0.0                 0                 1  \n",
       "1001020200         0.0                 0                 1  \n",
       "1001020300         0.7                 0                 1  \n",
       "1001020400         0.0                 1                 0  \n",
       "1001020500         0.0                 0                 1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe to use in logistic and SVM models\n",
    "df_17_model = df_17_cln.copy()\n",
    "\n",
    "# Eliminate non-useful and redundant variables\n",
    "del df_17_model['State'] # encoding would result in too many added variables\n",
    "del df_17_model['County'] # encoding would result in too many added variables\n",
    "del df_17_model['Men'] # redundant to keep men and women\n",
    "del df_17_model['Unemployment'] # already encoded to binary\n",
    "del df_17_model['ChildPoverty'] # already encoded to binary\n",
    "\n",
    "# Eliminate more variables based on correlation plot (could maybe remove more)\n",
    "del df_17_model['IncomeErr'] # only need to keep one income-related variable\n",
    "del df_17_model['IncomePerCap'] # only need to keep one income-related variable\n",
    "del df_17_model['IncomePerCapErr'] # only need to keep one income-related variable\n",
    "del df_17_model['Transit'] # drive and transit were essentially inverses\n",
    "del df_17_model['PublicWork'] # private and public work were essentially inverses\n",
    "\n",
    "# All remaining variables are ints or floats so we do not have to do one-hot encoding\n",
    "\n",
    "# Convert columns to percentages for consistency\n",
    "df_17_model['Women'] = round(df_17_model['Women']/df_17_model['TotalPop']*100,1)\n",
    "df_17_model['VotingAgeCitizen'] = round(df_17_model['VotingAgeCitizen']/df_17_model['TotalPop']*100,1)\n",
    "df_17_model['Employed'] = round(df_17_model['Employed']/df_17_model['TotalPop']*100,1)\n",
    "\n",
    "print(df_17_model.info())\n",
    "df_17_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y variables to use in models\n",
    "# y_u is for unemployment, y_cp is for child poverty\n",
    "if 'HighUnemployment' in df_17_model:\n",
    "    y_u = df_17_model['HighUnemployment'].values # get the labels we want\n",
    "    del df_17_model['HighUnemployment'] # get rid of the class label\n",
    "if 'HighChildPoverty' in df_17_model:\n",
    "    y_cp = df_17_model['HighChildPoverty'].values # get the labels we want\n",
    "    del df_17_model['HighChildPoverty'] # get rid of the class label\n",
    "X = df_17_model.values # use everything else to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 2:</b> Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final dataset used for classification is very similar to the full dataset provided by the U.S. Census Bureau. The differences are that a few variables have been removed due to redundancy, three variables have been converted to percentages rather than counts (Women, VotingAgeCitizen, and Employed), and our target class variables of Unemployment and ChildPoverty have been converted to binary indicator variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Attribute | Data Type | Description |\n",
    "|-----------|-----------|-------------|\n",
    "| TotalPop | Integer | Total population of the census area |\n",
    "| Women | Decimal | Percentage of total population that are women |\n",
    "| Hispanic | Decimal | Percentage of population that is Hispanic/Latino |\n",
    "| White | Decimal | Percentage of population that is white |\n",
    "| Black | Decimal | Percentage of population that is black |\n",
    "| Native | Decimal | Percent of population that is Native American |\n",
    "| Asian | Decimal | Percent of population that is Asian |\n",
    "| Pacific | Decimal | Percent of population that is Native Hawaiian or other Pacific Islander |\n",
    "| VotingAgeCitizen | Decimal | Percentage of population that are voting age citizens |\n",
    "| Income | Decimal | Median household income in USD ($) |\n",
    "| Poverty | Decimal | Percentage of population under the poverty level |\n",
    "| Professional | Decimal | Percent employed in management, business, science, and arts |\n",
    "| Service | Decimal | Percent employed in service jobs |\n",
    "| Office | Decimal | Percent employed in sales and office jobs |\n",
    "| Construction | Decimal | Percent employed in natural resources, construction, and maintenance |\n",
    "| Production | Decimal | Percent employed in production, transportation, and material movement |\n",
    "| Drive | Decimal | Percent commuting alone in a car, van, or truck |\n",
    "| Carpool | Decimal | Percent carpooling in a car, van, or truck |\n",
    "| Walk | Decimal | Percent walking to work |\n",
    "| OtherTransp | Decimal | Percent commuting via other means |\n",
    "| WorkAtHome | Decimal | Percentage working at home |\n",
    "| MeanCommute | Decimal | Mean commute time in minutes |\n",
    "| Employed | Decimal | Percentage of people employed (16+) |\n",
    "| PrivateWork | Decimal | Percentage employed in private industry |\n",
    "| SelfEmployed | Decimal | Percentage self-employed |\n",
    "| FamilyWork | Decimal | Percentage in unpaid family work |\n",
    "| HighUnemployment | Binary | Indication of a high rate of unemployment for the census tract |\n",
    "| HighChildPoverty | Binary | Indication of a high rate of children under the poverty level |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 3:</b> Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary evaluation metric we will use for our classification tasks is accuracy, but we will examine precision and recall as well. Accuracy itself is appropriate for any classification task, as it measures what percentage of the observations were classified correctly. Precision and recall, however, are most appropriate for binary classification problems, which we are performing here. We can use the confusion matrix below to define formulas for precision and recall:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| * | Predicted: High | Predicted: Low | \n",
    "|-----|------|-----|\n",
    "| **Actual: High** | TP | FN |\n",
    "| **Actual: Low** | FP | TN |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have $Precision = \\frac{TP}{TP+FP}$ and $Recall = \\frac{TP}{TP+FN}$. This means that high precision corresponds to low false positives, and high recall means low false negatives.\n",
    "\n",
    "Accuracy is already a good metric for our dataset, because there is no class imbalance. We have defined our target class variables to be split such that half of the observations are considered to have high unemployment and half have low unemployment, and similarly for child poverty. Problems often arise using accuracy when there is large class imbalance, but if a classifier tried to predict the same class for all observations in our dataset, it would only attain 50% accuracy. Thus if we see accuracies much higher than 50%, this is a good indication that the models are performing well.\n",
    "\n",
    "Precision and recall are also helpful to us based on the people who might be using these models. If a model attains high precision, i.e. there are few false positives, this means that the model did not flag many census tracts that actually had low unemployment or child poverty as ones needing aid. High precision would be good for an organization that has limited resources, i.e. they can only help so many neighborhoods, so they want to make sure the ones they target are actually in need of economic development or aid.\n",
    "\n",
    "On the other hand, if a model has high recall, i.e. there are few false negatives, this means that when census tracts have high unemployment or child poverty the model correctly identifies them. This would be appropriate for an organization that has extensive resources that wants to aid in all areas that need it, or at least identify all of those areas for future development.\n",
    "\n",
    "Therefore we will look at accuracy, precision and recall for our classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 4:</b> Choose the method you will use for dividing your data into training and\n",
    "testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why\n",
    "your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method used to divide our data into training and testing split is stratified shuffle split. Unlike the k fold stratified split it splits once but shuffles the data before the split. Here the sklearn allows us to pick the number of splits. The cv object is a combination of stratified k fold and stratified randomized folds and the folds are preserved per the samples on each classification. However in the stratified shuffle split the data overlap in folds.\n",
    "https://www.programcreek.com/python/example/91149/sklearn.model_selection.StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from IPython.html import widgets \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from time import time\n",
    "\n",
    "cv_u = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, train_size=0.8)\n",
    "cv_u.get_n_splits(X,y_u)\n",
    "\n",
    "for trainidx, testidx in cv_u.split(X,y_u):\n",
    "    X_trainU = X[trainidx] \n",
    "    X_testU = X[testidx] \n",
    "    y_trainU = y_u[trainidx]\n",
    "    y_testU = y_u[testidx]\n",
    "\n",
    "cv_cp = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, train_size=0.8)\n",
    "cv_cp.get_n_splits(X,y_cp)\n",
    "\n",
    "for trainidx, testidx in cv_cp.split(X,y_cp):\n",
    "    X_trainCP = X[trainidx] \n",
    "    X_testCP = X[testidx] \n",
    "    y_trainCP = y_cp[trainidx]\n",
    "    y_testCP = y_cp[testidx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 5:</b> Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN model for predicting unemployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier with 1 neighbors is: 0.61\n",
      "Precision of classifier with 1 neighbors is: 0.61\n",
      "Recall of classifier with 1 neighbors is: 0.59\n",
      "Accuracy of classifier with 2 neighbors is: 0.62\n",
      "Precision of classifier with 2 neighbors is: 0.70\n",
      "Recall of classifier with 2 neighbors is: 0.40\n",
      "Accuracy of classifier with 3 neighbors is: 0.64\n",
      "Precision of classifier with 3 neighbors is: 0.65\n",
      "Recall of classifier with 3 neighbors is: 0.60\n",
      "Accuracy of classifier with 4 neighbors is: 0.64\n",
      "Precision of classifier with 4 neighbors is: 0.70\n",
      "Recall of classifier with 4 neighbors is: 0.48\n",
      "Accuracy of classifier with 5 neighbors is: 0.65\n",
      "Precision of classifier with 5 neighbors is: 0.66\n",
      "Recall of classifier with 5 neighbors is: 0.61\n",
      "Accuracy of classifier with 6 neighbors is: 0.66\n",
      "Precision of classifier with 6 neighbors is: 0.71\n",
      "Recall of classifier with 6 neighbors is: 0.53\n",
      "Accuracy of classifier with 7 neighbors is: 0.66\n",
      "Precision of classifier with 7 neighbors is: 0.67\n",
      "Recall of classifier with 7 neighbors is: 0.62\n",
      "Accuracy of classifier with 8 neighbors is: 0.67\n",
      "Precision of classifier with 8 neighbors is: 0.71\n",
      "Recall of classifier with 8 neighbors is: 0.55\n",
      "Accuracy of classifier with 9 neighbors is: 0.67\n",
      "Precision of classifier with 9 neighbors is: 0.68\n",
      "Recall of classifier with 9 neighbors is: 0.62\n",
      "Accuracy of classifier with 10 neighbors is: 0.67\n",
      "Precision of classifier with 10 neighbors is: 0.71\n",
      "Recall of classifier with 10 neighbors is: 0.56\n",
      "Accuracy of classifier with 11 neighbors is: 0.67\n",
      "Precision of classifier with 11 neighbors is: 0.68\n",
      "Recall of classifier with 11 neighbors is: 0.62\n",
      "Accuracy of classifier with 12 neighbors is: 0.67\n",
      "Precision of classifier with 12 neighbors is: 0.71\n",
      "Recall of classifier with 12 neighbors is: 0.57\n",
      "Accuracy of classifier with 13 neighbors is: 0.67\n",
      "Precision of classifier with 13 neighbors is: 0.69\n",
      "Recall of classifier with 13 neighbors is: 0.62\n",
      "Accuracy of classifier with 14 neighbors is: 0.67\n",
      "Precision of classifier with 14 neighbors is: 0.71\n",
      "Recall of classifier with 14 neighbors is: 0.58\n",
      "Accuracy of classifier with 15 neighbors is: 0.67\n",
      "Precision of classifier with 15 neighbors is: 0.69\n",
      "Recall of classifier with 15 neighbors is: 0.62\n",
      "Accuracy of classifier with 16 neighbors is: 0.68\n",
      "Precision of classifier with 16 neighbors is: 0.71\n",
      "Recall of classifier with 16 neighbors is: 0.58\n",
      "Accuracy of classifier with 17 neighbors is: 0.68\n",
      "Precision of classifier with 17 neighbors is: 0.69\n",
      "Recall of classifier with 17 neighbors is: 0.62\n",
      "Accuracy of classifier with 18 neighbors is: 0.68\n",
      "Precision of classifier with 18 neighbors is: 0.71\n",
      "Recall of classifier with 18 neighbors is: 0.58\n",
      "Accuracy of classifier with 19 neighbors is: 0.68\n",
      "Precision of classifier with 19 neighbors is: 0.70\n",
      "Recall of classifier with 19 neighbors is: 0.62\n"
     ]
    }
   ],
   "source": [
    "for K in range(1,20):\n",
    "    clf = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='euclidean')\n",
    "    clf.fit(X_trainU,y_trainU)\n",
    "    y_hatU = clf.predict(X_testU)\n",
    "    accuracy = accuracy_score(y_testU,y_hatU) \n",
    "    precision = precision_score(y_testU, y_hatU)\n",
    "    recall = recall_score(y_testU, y_hatU)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.2f'%(K,accuracy))\n",
    "    print('Precision of classifier with %d neighbors is: %.2f'%(K,precision))\n",
    "    print('Recall of classifier with %d neighbors is: %.2f'%(K,recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN for Child Poverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier with 1 neighbors is: 0.73\n",
      "Precision of classifier with 1 neighbors is: 0.73\n",
      "Recall of classifier with 1 neighbors is: 0.72\n",
      "Accuracy of classifier with 2 neighbors is: 0.73\n",
      "Precision of classifier with 2 neighbors is: 0.82\n",
      "Recall of classifier with 2 neighbors is: 0.59\n",
      "Accuracy of classifier with 3 neighbors is: 0.76\n",
      "Precision of classifier with 3 neighbors is: 0.76\n",
      "Recall of classifier with 3 neighbors is: 0.75\n",
      "Accuracy of classifier with 4 neighbors is: 0.76\n",
      "Precision of classifier with 4 neighbors is: 0.81\n",
      "Recall of classifier with 4 neighbors is: 0.68\n",
      "Accuracy of classifier with 5 neighbors is: 0.77\n",
      "Precision of classifier with 5 neighbors is: 0.78\n",
      "Recall of classifier with 5 neighbors is: 0.76\n",
      "Accuracy of classifier with 6 neighbors is: 0.77\n",
      "Precision of classifier with 6 neighbors is: 0.81\n",
      "Recall of classifier with 6 neighbors is: 0.71\n",
      "Accuracy of classifier with 7 neighbors is: 0.78\n",
      "Precision of classifier with 7 neighbors is: 0.78\n",
      "Recall of classifier with 7 neighbors is: 0.77\n",
      "Accuracy of classifier with 8 neighbors is: 0.78\n",
      "Precision of classifier with 8 neighbors is: 0.81\n",
      "Recall of classifier with 8 neighbors is: 0.73\n",
      "Accuracy of classifier with 9 neighbors is: 0.78\n",
      "Precision of classifier with 9 neighbors is: 0.79\n",
      "Recall of classifier with 9 neighbors is: 0.77\n",
      "Accuracy of classifier with 10 neighbors is: 0.78\n",
      "Precision of classifier with 10 neighbors is: 0.81\n",
      "Recall of classifier with 10 neighbors is: 0.74\n",
      "Accuracy of classifier with 11 neighbors is: 0.78\n",
      "Precision of classifier with 11 neighbors is: 0.79\n",
      "Recall of classifier with 11 neighbors is: 0.77\n",
      "Accuracy of classifier with 12 neighbors is: 0.78\n",
      "Precision of classifier with 12 neighbors is: 0.81\n",
      "Recall of classifier with 12 neighbors is: 0.75\n",
      "Accuracy of classifier with 13 neighbors is: 0.78\n",
      "Precision of classifier with 13 neighbors is: 0.79\n",
      "Recall of classifier with 13 neighbors is: 0.77\n",
      "Accuracy of classifier with 14 neighbors is: 0.79\n",
      "Precision of classifier with 14 neighbors is: 0.81\n",
      "Recall of classifier with 14 neighbors is: 0.75\n",
      "Accuracy of classifier with 15 neighbors is: 0.79\n",
      "Precision of classifier with 15 neighbors is: 0.79\n",
      "Recall of classifier with 15 neighbors is: 0.78\n",
      "Accuracy of classifier with 16 neighbors is: 0.79\n",
      "Precision of classifier with 16 neighbors is: 0.81\n",
      "Recall of classifier with 16 neighbors is: 0.76\n",
      "Accuracy of classifier with 17 neighbors is: 0.79\n",
      "Precision of classifier with 17 neighbors is: 0.79\n",
      "Recall of classifier with 17 neighbors is: 0.78\n",
      "Accuracy of classifier with 18 neighbors is: 0.79\n",
      "Precision of classifier with 18 neighbors is: 0.81\n",
      "Recall of classifier with 18 neighbors is: 0.76\n",
      "Accuracy of classifier with 19 neighbors is: 0.79\n",
      "Precision of classifier with 19 neighbors is: 0.80\n",
      "Recall of classifier with 19 neighbors is: 0.78\n",
      "Accuracy of classifier with 20 neighbors is: 0.79\n",
      "Precision of classifier with 20 neighbors is: 0.81\n",
      "Recall of classifier with 20 neighbors is: 0.76\n",
      "Accuracy of classifier with 21 neighbors is: 0.79\n",
      "Precision of classifier with 21 neighbors is: 0.80\n",
      "Recall of classifier with 21 neighbors is: 0.78\n",
      "Accuracy of classifier with 22 neighbors is: 0.79\n",
      "Precision of classifier with 22 neighbors is: 0.81\n",
      "Recall of classifier with 22 neighbors is: 0.77\n",
      "Accuracy of classifier with 23 neighbors is: 0.79\n",
      "Precision of classifier with 23 neighbors is: 0.80\n",
      "Recall of classifier with 23 neighbors is: 0.78\n",
      "Accuracy of classifier with 24 neighbors is: 0.79\n",
      "Precision of classifier with 24 neighbors is: 0.81\n",
      "Recall of classifier with 24 neighbors is: 0.77\n"
     ]
    }
   ],
   "source": [
    "for K in range(1,25):\n",
    "    clf = KNeighborsClassifier(n_neighbors=K, weights='uniform', metric='euclidean')\n",
    "    clf.fit(X_trainCP,y_trainCP)\n",
    "    y_hatCP = clf.predict(X_testCP)\n",
    "    accuracy = accuracy_score(y_testCP,y_hatCP) \n",
    "    precision = precision_score(y_testCP, y_hatCP)\n",
    "    recall = recall_score(y_testCP, y_hatCP)\n",
    "    print('Accuracy of classifier with %d neighbors is: %.2f'%(K,accuracy))\n",
    "    print('Precision of classifier with %d neighbors is: %.2f'%(K,precision))\n",
    "    print('Recall of classifier with %d neighbors is: %.2f'%(K,recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes for predicting Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Bernoulli Model: 0.698\n",
      "Precision for Bernoulli Model: 0.683\n",
      "Recall for Bernoulli Model: 0.72\n",
      "Latency in ms for Bernoulli Model: 5.8\n",
      "Confusion matrix for Bernoulli Model:: [[5000 2397]\n",
      " [2011 5170]]\n",
      "**************************************\n",
      "Accuracy for Multinomial Model: 0.646\n",
      "Precision for Multinomial Model: 0.635\n",
      "Recall for Multinomial Model: 0.659\n",
      "Latency in ms for Multinomial Model: 0.7\n",
      "Confusion matrix for Multinomial Model:: [[4680 2717]\n",
      " [2448 4733]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Bernoulli Model:\n",
    "clf_bnb = BernoulliNB(alpha=0.001, binarize=10)\n",
    "clf_bnb.fit(X_trainU,y_trainU)\n",
    "start = time()\n",
    "y_hatU = clf_bnb.predict(X_testU)\n",
    "end = time()\n",
    "accuracy = round(accuracy_score(y_testU, y_hatU), 3)\n",
    "precision = round(precision_score(y_testU, y_hatU), 3)\n",
    "recall = round(recall_score(y_testU, y_hatU), 3)\n",
    "print('Accuracy for Bernoulli Model:', accuracy)\n",
    "print('Precision for Bernoulli Model:', precision)\n",
    "print('Recall for Bernoulli Model:', recall)\n",
    "print('Latency in ms for Bernoulli Model:', round((end - start)*1000, 1))\n",
    "print (\"Confusion matrix for Bernoulli Model::\", confusion_matrix(y_testU, y_hatU))\n",
    "print('**************************************')\n",
    "\n",
    "#Multinomial Model:\n",
    "clf_mnb = MultinomialNB(alpha=0.001)\n",
    "clf_mnb.fit(X_trainU,y_trainU)\n",
    "start = time()\n",
    "y_hatU = clf_mnb.predict(X_testU)\n",
    "end = time()\n",
    "accuracy = round(accuracy_score(y_testU,y_hatU), 3)\n",
    "precision = round(precision_score(y_testU, y_hatU), 3)\n",
    "recall = round(recall_score(y_testU, y_hatU), 3)\n",
    "print('Accuracy for Multinomial Model:', accuracy)\n",
    "print('Precision for Multinomial Model:', precision)\n",
    "print('Recall for Multinomial Model:', recall)\n",
    "print('Latency in ms for Multinomial Model:', round((end - start)*1000, 1))\n",
    "print (\"Confusion matrix for Multinomial Model::\", confusion_matrix(y_testU, y_hatU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes for predicting Child Poverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Bernoulli Model: 0.858\n",
      "Precision for Bernoulli Model: 0.823\n",
      "Recall for Bernoulli Model: 0.912\n",
      "Latency in ms for Bernoulli Model: 5.1\n",
      "Confusion matrix for Bernoulli Model:: [[5874 1430]\n",
      " [ 642 6632]]\n",
      "**************************************\n",
      "Accuracy for Multinomial Model: 0.711\n",
      "Precision for Multinomial Model: 0.707\n",
      "Recall for Multinomial Model: 0.72\n",
      "Latency in ms for Multinomial Model: 0.8\n",
      "Confusion matrix for Multinomial Model:: [[5135 2169]\n",
      " [2039 5235]]\n"
     ]
    }
   ],
   "source": [
    "#Bernoulli Model:\n",
    "clf_bnb = BernoulliNB(alpha=0.001, binarize=10)\n",
    "clf_bnb.fit(X_trainCP,y_trainCP)\n",
    "start = time()\n",
    "y_hatCP = clf_bnb.predict(X_testCP)\n",
    "end = time()\n",
    "accuracy = round(accuracy_score(y_testCP,y_hatCP), 3)\n",
    "precision = round(precision_score(y_testCP,y_hatCP), 3)\n",
    "recall = round(recall_score(y_testCP,y_hatCP), 3)\n",
    "print('Accuracy for Bernoulli Model:', accuracy)\n",
    "print('Precision for Bernoulli Model:', precision)\n",
    "print('Recall for Bernoulli Model:', recall)\n",
    "print('Latency in ms for Bernoulli Model:', round((end - start)*1000, 1))\n",
    "print (\"Confusion matrix for Bernoulli Model::\", confusion_matrix(y_testCP, y_hatCP))\n",
    "print('**************************************')\n",
    "\n",
    "#Multinomial Model:\n",
    "clf_mnb = MultinomialNB(alpha=0.001)\n",
    "clf_mnb.fit(X_trainCP,y_trainCP)\n",
    "start = time()\n",
    "y_hatCP = clf_mnb.predict(X_testCP)\n",
    "end = time()\n",
    "accuracy = round(accuracy_score(y_testCP,y_hatCP), 3)\n",
    "precision = round(precision_score(y_testCP,y_hatCP), 3)\n",
    "recall = round(recall_score(y_testCP,y_hatCP), 3)\n",
    "print('Accuracy for Multinomial Model:', accuracy)\n",
    "print('Precision for Multinomial Model:', precision)\n",
    "print('Recall for Multinomial Model:', recall)\n",
    "print('Latency in ms for Multinomial Model:', round((end - start)*1000, 1))\n",
    "print (\"Confusion matrix for Multinomial Model::\", confusion_matrix(y_testCP, y_hatCP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest for Unemployment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Model:  0.739\n",
      "Precision for Random Forest Model: 0.755\n",
      "Recall for Random Forest Model: 0.697\n",
      "Latency in ms for Random Forest Model: 27.0\n",
      " Confusion matrix: [[5768 1629]\n",
      " [2174 5007]]\n"
     ]
    }
   ],
   "source": [
    "#Import the RF library from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from time import time\n",
    "\n",
    "# Supervised transformation based on random forests\n",
    "rfclf = RandomForestClassifier(max_depth=5, n_estimators=10)\n",
    "#Fitting RF model on training data\n",
    "rfclf.fit(X_trainU, y_trainU)\n",
    "\n",
    "# The random forest model prediction \n",
    "start = time()\n",
    "y_pred_rf = rfclf.predict_proba(X_testU)[0:10]\n",
    "preds = rfclf.predict(X_testU)\n",
    "end = time()\n",
    "accuracy = round(accuracy_score(y_testU,preds), 3)\n",
    "precision = round(precision_score(y_testU,preds), 3)\n",
    "recall = round(recall_score(y_testU,preds), 3)\n",
    "print (\"Accuracy for Random Forest Model: \", accuracy)\n",
    "print('Precision for Random Forest Model:', precision)\n",
    "print('Recall for Random Forest Model:', recall)\n",
    "print('Latency in ms for Random Forest Model:', round((end - start)*1000, 1))\n",
    "print (\" Confusion matrix:\", confusion_matrix(y_testU, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest for Child Poverty prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Model:  0.881\n",
      "Precision for Random Forest Model: 0.867\n",
      "Recall for Random Forest Model: 0.899\n",
      "Latency in ms for Random Forest Model: 18.9\n",
      " Confusion matrix  [[6305  999]\n",
      " [ 737 6537]]\n"
     ]
    }
   ],
   "source": [
    "#Import the RF library from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from time import time\n",
    "\n",
    "# Supervised transformation based on random forests\n",
    "rfclf = RandomForestClassifier(max_depth=5, n_estimators=10)\n",
    "#Fitting RF model on training data\n",
    "rfclf.fit(X_trainCP, y_trainCP)\n",
    "\n",
    "# The random forest model prediction \n",
    "start = time()\n",
    "y_pred_rf = rfclf.predict_proba(X_testCP)[0:10]\n",
    "preds = rfclf.predict(X_testCP)\n",
    "end = time()\n",
    "accuracy = round(accuracy_score(y_testCP,preds), 3)\n",
    "precision = round(precision_score(y_testCP,preds), 3)\n",
    "recall = round(recall_score(y_testCP,preds), 3)\n",
    "print (\"Accuracy for Random Forest Model: \", accuracy)\n",
    "print('Precision for Random Forest Model:', precision)\n",
    "print('Recall for Random Forest Model:', recall)\n",
    "print('Latency in ms for Random Forest Model:', round((end - start)*1000, 1))\n",
    "print (\" Confusion matrix \", confusion_matrix(y_testCP, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 6:</b> Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 7:</b> Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniquesbe sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 8:</b> Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 9:</b> How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Rubric 10:</b> You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
